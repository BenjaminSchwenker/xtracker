{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Graph Neural Network Trigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import yaml\n",
    "\n",
    "from nb_utils import (compute_metrics, plot_metrics, draw_sample_xy, draw_sample, load_summaries)\n",
    "\n",
    "from xtracker.utils import dotdict\n",
    "from itertools import cycle\n",
    "from xtracker.datasets import get_data_loaders\n",
    "from xtracker.gnn_tracking.TrackingGame import TrackingGame as Game\n",
    "from xtracker.gnn_tracking.pytorch.NNet import NNetWrapper\n",
    "from xtracker.gnn_tracking.pytorch.NNet import NNetWrapperTrigger\n",
    "from xtracker.gnn_tracking.ImTracker import ImTracker\n",
    "from xtracker.gnn_tracking.TrackingSolver import TrackingSolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit CPU usage on Jupyter\n",
    "os.environ['OMP_NUM_THREADS'] = '4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatureScales(config_path):\n",
    "    \n",
    "    config_path = os.path.expandvars(config_path)\n",
    "    with open(config_path) as f:\n",
    "        config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "    n_phi_sections = 1\n",
    "    feature_scale_r = config['selection']['feature_scale_r']\n",
    "    feature_scale_phi = config['selection']['feature_scale_phi']\n",
    "    feature_scale_z = config['selection']['feature_scale_z']\n",
    "\n",
    "    feature_scale = np.array([feature_scale_r, np.pi / n_phi_sections / feature_scale_phi, feature_scale_z])\n",
    "    return feature_scale \n",
    "\n",
    "def getGame(config_path):\n",
    "    \n",
    "    config_path = os.path.expandvars(config_path)\n",
    "    with open(config_path) as f:\n",
    "        config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "    data_args = dotdict( config['data'] )\n",
    "        \n",
    "    train_data_loader, valid_data_loader = get_data_loaders(**data_args,  input_dir=config['global']['graph_dir'])\n",
    "    assert valid_data_loader is not None\n",
    "    assert train_data_loader is not None\n",
    "\n",
    "    valid_data_loader = cycle(valid_data_loader)\n",
    "    train_data_loader = cycle(train_data_loader)\n",
    "\n",
    "    game = Game(train_data_loader, valid_data_loader)\n",
    "    \n",
    "    return game \n",
    "\n",
    "def setupTracker(game, config_path):\n",
    "    \n",
    "    config_path_tracker = os.path.expandvars(config_path)\n",
    "    with open(config_path) as f:\n",
    "        config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "    # Load trained neural net\n",
    "    n1 = NNetWrapper()\n",
    "    checkpoint_dir = os.path.expandvars(config['training']['checkpoint'])\n",
    "    n1.load_checkpoint(checkpoint_dir, 'best.pth.tar')\n",
    "\n",
    "    # Built a tracker\n",
    "    tracker_args = dotdict(config['model'])\n",
    "    tracker = ImTracker(game, n1, tracker_args)\n",
    "\n",
    "    return tracker\n",
    "\n",
    "\n",
    "def setupTrigger(config_path):\n",
    "    \n",
    "    config_path = os.path.expandvars(config_path)\n",
    "    with open(config_path) as f:\n",
    "        config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    \n",
    "    # Load neural net\n",
    "    trigger = NNetWrapperTrigger()\n",
    "    checkpoint_dir = os.path.expandvars(config['training']['checkpoint'])\n",
    "    trigger.load_checkpoint(checkpoint_dir, 'best.pth.tar')\n",
    "    \n",
    "    return trigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path_tracker = './../examples/configs/belle2_vtx.yaml'\n",
    "config_path_trigger = './../examples/configs/belle2_vtx_trigger.yaml'\n",
    "\n",
    "game = getGame(config_path_trigger)\n",
    "feature_scale = getFeatureScales(config_path_trigger)\n",
    "tracker = setupTracker(game, config_path_tracker)\n",
    "trigger = setupTrigger(config_path_trigger)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "x = self.tracker.embed_hits(board)\n",
    "\n",
    "\n",
    "pred_trig = self.player1.predict(x)[0, 0]\n",
    "true_trig = board.trig.numpy()[0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate tracker and tracker on individual events "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "board = game.getInitBoard(training=False)\n",
    "\n",
    "pred, score, _ = tracker.process(board)   \n",
    "x = tracker.embed_hits(board)\n",
    "pred_trig = trigger.predict(x)[0, 0]\n",
    "true_trig = board.trig.numpy()[0,0]\n",
    "\n",
    "print('score=', score)\n",
    "print('pred trigger ', pred_trig)\n",
    "print('true trigger ', true_trig)\n",
    "\n",
    "draw_sample_xy(board.x * feature_scale, board.edge_index, pred, board.y, cut=0.5, mconly=False, fullonly=False,\n",
    "              figsize=(9, 9)\n",
    ")\n",
    "draw_sample(board.x * feature_scale, board.edge_index, pred, board.y, cut=0.5, mconly=False, fullonly=False, \n",
    "           figsize=(9, 6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate trigger with statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sample(n=200):\n",
    "    preds, targets = [], []\n",
    "    for _ in range(n):  \n",
    "        board = game.getInitBoard(training=False)\n",
    "        x = tracker.embed_hits(board)\n",
    "        pred_trig = trigger.predict(x)[0, 0]\n",
    "        true_trig = board.trig.numpy()[0, 0]\n",
    "              \n",
    "        preds.append(pred_trig)\n",
    "        targets.append(true_trig)\n",
    "        \n",
    "    return preds, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Apply the model\n",
    "test_preds, test_targets = predict_sample(n=200) \n",
    "\n",
    "test_metrics = compute_metrics([test_preds], [test_targets], threshold=0.5)\n",
    "print('Accuracy:  %.4f' % test_metrics.accuracy)\n",
    "print('Precision: %.4f' % test_metrics.precision)\n",
    "print('Recall:    %.4f' % test_metrics.recall)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics([test_preds], [test_targets], test_metrics, figsize=(9, 6))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Belle2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
