{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hit graph construction\n",
    "\n",
    "This is a notebook for developing and analyzing the procedure for constructing hit graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from xtracker.graph_creation import (\n",
    "    calc_dphi, calc_eta, construct_graph, select_hits, split_detector_sections, form_layer_pairs, \n",
    "    construct_segments\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the event data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"/home/benjamin/xtracker/examples/data/events_belle2_vtx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evtid = 300\n",
    "\n",
    "hits = pd.read_hdf(os.path.expandvars( input_dir + '/event_id_{}.h5'.format(evtid+1) ), 'hits')\n",
    "truth = pd.read_hdf(os.path.expandvars( input_dir + '/event_id_{}.h5'.format(evtid+1) ), 'truth')\n",
    "particles = pd.read_hdf(os.path.expandvars( input_dir + '/event_id_{}.h5'.format(evtid+1) ), 'particles')\n",
    "trigger = pd.read_hdf(os.path.expandvars( input_dir + '/event_id_{}.h5'.format(evtid+1) ), 'trigger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "particles.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hit selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_min = 0. # GeV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits = (select_hits(hits, truth, particles, pt_min=pt_min)\n",
    "        .assign(evtid=0)\n",
    "        .reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geometry ID pairs\n",
    "\n",
    "We use geometry IDs to select initial set of hit pair segments.\n",
    "For now we're starting with barrel hits only and can use the layer number as the ID.\n",
    "We'll then use consecutive layer numbers as the criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_det_layers = 5\n",
    "segment_type = 'all'\n",
    "\n",
    "\n",
    "layer_pairs = form_layer_pairs(n_det_layers, segment_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment construction\n",
    "\n",
    "Now for every layer pair we construct hit-pair segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segments(hits, layer_pairs):\n",
    "\n",
    "    # Group hits by geometry ID\n",
    "    layer_groups = hits.groupby('layer')\n",
    "\n",
    "    segments = []\n",
    "    \n",
    "    for (layer1, layer2) in layer_pairs:\n",
    "        # Find and join all hit pairs\n",
    "        try:\n",
    "            hits1 = layer_groups.get_group(layer1)\n",
    "            hits2 = layer_groups.get_group(layer2)\n",
    "        # If an event has no hits on a layer, we get a KeyError.\n",
    "        # In that case we just skip to the next layer pair\n",
    "        except KeyError as e:\n",
    "            continue\n",
    "        # Construct the segments\n",
    "        \n",
    "        # Start with all possible pairs of hits\n",
    "        keys = ['evtid', 'r', 'phi', 'z', 'particle_id', 'hit_id', 'layer']\n",
    "        hit_pairs = hits1[keys].reset_index().merge(\n",
    "            hits2[keys].reset_index(), on='evtid', suffixes=('_1', '_2'))\n",
    "        \n",
    "        # Compute line through the points\n",
    "        dphi = calc_dphi(hit_pairs.phi_1, hit_pairs.phi_2)\n",
    "        dz = hit_pairs.z_2 - hit_pairs.z_1\n",
    "        dr = hit_pairs.r_2 - hit_pairs.r_1\n",
    "        phi_slope = dphi / dr\n",
    "        z0 = hit_pairs.z_1 - hit_pairs.r_1 * dz / dr\n",
    "        \n",
    "        # We do not have good filter for same layer or ingoing edges\n",
    "        z0[ hit_pairs.layer_1 >= hit_pairs.layer_2 ] = 0.0 \n",
    "        phi_slope[ hit_pairs.layer_1 == hit_pairs.layer_2 ] = 0.0 \n",
    "        \n",
    "        # Identify the true pairs\n",
    "        y = (hit_pairs.particle_id_1 == hit_pairs.particle_id_2) & (hit_pairs.hit_id_1+1 == hit_pairs.hit_id_2)\n",
    "            \n",
    "        # Put the results in a new dataframe\n",
    "        segments.append(hit_pairs[['evtid', 'index_1', 'index_2', 'layer_1', 'layer_2']]\n",
    "                        .assign(dphi=dphi, dz=dz, dr=dr, y=y, phi_slope=phi_slope, z0=z0))\n",
    "        \n",
    "    return pd.concat(segments, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = get_segments(hits, layer_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the full segment distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "\n",
    "true_segs = segments[segments.y]\n",
    "fake_segs = segments[segments.y == False]\n",
    "\n",
    "plt.subplot(121)\n",
    "binning=dict(bins=150, range=(-2.2, 2.2))\n",
    "plt.hist(fake_segs.phi_slope, label='fake', log=True, **binning)\n",
    "plt.hist(true_segs.phi_slope, label='true', **binning)\n",
    "plt.xlabel('$\\Delta \\phi / \\Delta r$ [rad/mm]')\n",
    "plt.legend(loc=0)\n",
    "\n",
    "plt.subplot(122)\n",
    "binning=dict(bins=50, range=(-50, 50))\n",
    "plt.hist(fake_segs.z0, label='fake', log=True, **binning)\n",
    "plt.hist(true_segs.z0, label='true', **binning)\n",
    "plt.xlabel('$z_0$ [mm]')\n",
    "plt.legend(loc=0)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_segments(segments, phi_slope_min, phi_slope_max, z0_max):\n",
    "    sel_mask = ((segments.phi_slope > phi_slope_min) &\n",
    "                (segments.phi_slope < phi_slope_max) &\n",
    "                (segments.z0 < z0_max) &  (segments.z0 > -z0_max) )\n",
    "    return segments.assign(selected=sel_mask)\n",
    "\n",
    "def segment_efficiency(segments):\n",
    "    return (segments.y & segments.selected).sum() / segments.y.sum()\n",
    "\n",
    "def segment_purity(segment):\n",
    "    return (segments.y & segments.selected).sum() / segments.selected.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose some cuts\n",
    "phi_slope_min = -2.25\n",
    "phi_slope_max =  2.25\n",
    "z0_max =  100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = select_segments(segments, phi_slope_min=phi_slope_min,\n",
    "                           phi_slope_max=phi_slope_max, z0_max=z0_max)\n",
    "\n",
    "print('Selection efficiency %.4f purity %.4f' % (segment_efficiency(segments), segment_purity(segments)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eff = []\n",
    "pur = []\n",
    "\n",
    "for evtid in range(10):\n",
    "    \n",
    "    hits = pd.read_hdf(os.path.expandvars( input_dir + '/event_id_{}.h5'.format(evtid+1) ), 'hits')\n",
    "    truth = pd.read_hdf(os.path.expandvars( input_dir + '/event_id_{}.h5'.format(evtid+1) ), 'truth')\n",
    "    particles = pd.read_hdf(os.path.expandvars( input_dir + '/event_id_{}.h5'.format(evtid+1) ), 'particles')\n",
    "    \n",
    "    \n",
    "    hits = (select_hits(hits, truth, particles, pt_min=pt_min)\n",
    "        .assign(evtid=0)\n",
    "        .reset_index(drop=True))\n",
    "    \n",
    "    layer_pairs = form_layer_pairs(n_det_layers, segment_type)\n",
    "    \n",
    "    segments = get_segments(hits, layer_pairs)\n",
    "    \n",
    "    segments = select_segments(segments, phi_slope_min=phi_slope_min,\n",
    "                           phi_slope_max=phi_slope_max, z0_max=z0_max)\n",
    "    \n",
    "    true_segs = segments[segments.y]\n",
    "    \n",
    "    eff.append(segment_efficiency(segments))\n",
    "    pur.append(segment_purity(segments))\n",
    "\n",
    "print('Av. selection efficiency %.4f purity %.4f' % (np.mean(eff), (np.mean(pur))))\n",
    "\n",
    "\n",
    "    \n",
    "plt.figure(figsize=(14,6))\n",
    "\n",
    "plt.subplot(121)\n",
    "binning=dict(bins=50, range=(0.0, 1.0))\n",
    "plt.hist(eff, **binning)\n",
    "plt.xlabel('efficiency')\n",
    "plt.legend(loc=0)\n",
    "\n",
    "plt.subplot(122)\n",
    "binning=dict(bins=50, range=(0, 1.0))\n",
    "plt.hist(pur, **binning)\n",
    "plt.xlabel('purity')\n",
    "plt.legend(loc=0)\n",
    "\n",
    "plt.tight_layout()    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Belle2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
