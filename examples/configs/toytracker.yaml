# Global parameters 
global:
    n_events: 5000                                      # Number of events to simulate 
    rndseed: 12345                                      # Random seed 
    event_dir: ${HEP_DATA}/events_toytracker            # Path to Simulated events
    graph_dir: ${HEP_DATA}/hitgraphs_toytracker         # Path to hit graphs 
    saved_model: ${HEP_DATA}/saved_models/toytracker    # Path to saved model


# Event simulation configuration
simulation:
    p_min: 0.02      # GeV 
    p_max: 0.1 
    theta_min: 0.2967    
    theta_max: 2.62   
    num_tracks_min: 30
    num_tracks_max: 40 
    num_noise_min: 120
    num_noise_max: 180

# Graph building configuration
selection:
    n_det_layers: 6
    pt_min: 0. # GeV
    phi_slope_max: 0.1
    z0_max: 100
    n_phi_sections: 1 
    n_eta_sections: 1 
    eta_range: [-5, 5]
    segment_type: all
    feature_scale_r: 100.0
    feature_scale_phi: 1.0
    feature_scale_z: 100.0
    feature_scale_t: 1.0

training:
    numIters: 180             # Number of training iterations 
    numEps: 25                # Number of new games to simulate during a new iteration.
    maxlenOfQueue: 200000     # Number of new game examples (per iteration) to train the neural networks.
    arenaCompare: 512         # Number of games to played in arena for network evaluation 
    tempThreshold: 5          # Unused
    supervised_training: True
    checkpoint: ./temp_toytracker/
    load_model: False
    load_folder_file: !!python/tuple ['./temp_toytracker/','best.pth.tar']
    numItersForTrainExamplesHistory: 2 
    pre_scale_examples: 0.001 
    pre_stop_example: 0.0 

model: 
    nIter: 40
    verbose: False 
    mid_steps: 4
    noise_sigma: 0.0  
    update_e: False 

optimizer:
    name: Adam 
    lr: 0.0005 
    #dropout: 0.3
    epochs: 1
    batch_size: 1

data: 
    name: hitgraphs_sparse
    n_train: 8000
    n_valid: 1000
    batch_size: 1  